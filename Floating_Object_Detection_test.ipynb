{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nNVi1ldwg0P"
   },
   "source": [
    "# **FLOATING OBJECT DETECTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGTfVAbC649k"
   },
   "source": [
    "**About the dataset**\n",
    "\n",
    "\n",
    "1. Dataset size?\n",
    "2. Size of images?\n",
    "3. How many categories?\n",
    "4. Exist annotation file with no data\n",
    "5. Six categories: human, wind/sup-board, boat, bouy, sailboat, kayak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_AGGoxYw-6z"
   },
   "source": [
    "**[Download dataset](https://www.kaggle.com/datasets/jangsienicajzkowy/afo-aerial-dataset-of-floating-objects/data)**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DKjZI04svts3",
    "ExecuteTime": {
     "end_time": "2025-03-23T13:32:16.435720Z",
     "start_time": "2025-03-23T13:32:16.431415Z"
    }
   },
   "source": [
    "import shutil\n",
    "from pathlib import Path"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqfDovVgy_Dp"
   },
   "source": [
    "**Data path**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DB72kVt9zEvT",
    "ExecuteTime": {
     "end_time": "2025-03-23T13:32:16.439543Z",
     "start_time": "2025-03-23T13:32:16.436712Z"
    }
   },
   "source": [
    "# Image path of PART 1,2,3\n",
    "img_path_1 = 'dataset/PART_1/PART_1/images/'\n",
    "img_path_2 = 'dataset/PART_2/PART_2/images/'\n",
    "img_path_3 = 'dataset/PART_3/PART_3/images/'\n",
    "\n",
    "# Categories path\n",
    "# Categories: human, wind/sup-board, boat, bouy, sailboat, kayak\n",
    "categories_path = 'dataset/PART_1/PART_1/6categories/'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4HA049S2Ar25"
   },
   "source": [
    "**Split Data into Train, Test & Validation**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2dqKWAsNAq5L",
    "ExecuteTime": {
     "end_time": "2025-03-23T13:32:16.448538Z",
     "start_time": "2025-03-23T13:32:16.441528Z"
    }
   },
   "source": [
    "# Split into three parts: the training (67,4% of objects), the test (19,12% of objects),\n",
    "# and the validation set (13,48% of objects). In order to prevent overfitting of the model to the given data,\n",
    "# the test set contains selected frames from nine videos that were not used in either the training or validation sets.\n",
    "\n",
    "# Split image to : dataset/working/images\n",
    "# Split annotation to: dataset/working/labels\n",
    "\n",
    "def split_data(file_list, img_path, ann_path, mode):\n",
    "    #Check if we have our mode folders\n",
    "    images_working_folder = Path( 'dataset/working/images/'+  mode)\n",
    "    if not images_working_folder.exists():\n",
    "        print(f\"Path {images_working_folder} does not exit\")\n",
    "        os.makedirs(images_working_folder)\n",
    "\n",
    "    labels_working_folder = Path('dataset/working/labels/' + mode)\n",
    "    if not labels_working_folder.exists():\n",
    "        print(f\"Path {labels_working_folder} does not exit\")\n",
    "        os.makedirs(labels_working_folder)\n",
    "\n",
    "    #Creates the name of our label file from the img name and creates our source file\n",
    "    for file in file_list:\n",
    "        name = file.replace('.jpg', '')\n",
    "        img_src_file = str(img_path) + '/' + name + '.jpg'\n",
    "        annot_src_file = str(ann_path) + '/' + name + '.txt'\n",
    "        \n",
    "        if Path(img_src_file).exists() and Path(annot_src_file).exists():\n",
    "            #move image\n",
    "            IMG_DIR = 'dataset/working/images/' + mode\n",
    "            img_dest_file = str(IMG_DIR) + '/' + name + '.jpg'\n",
    "            if os.path.isfile(img_src_file) and not Path(img_dest_file).exists():\n",
    "                shutil.move(img_src_file, img_dest_file)\n",
    "    \n",
    "            # Copy annotations\n",
    "            ANNOT_DIR = 'dataset/working/labels/' + mode\n",
    "            annot_dest_file = str(ANNOT_DIR) + '/' + name + '.txt'\n",
    "            if os.path.isfile(annot_src_file) and not Path(annot_dest_file).exists():\n",
    "                shutil.move(annot_src_file, annot_dest_file)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-g6Po3VCLX9",
    "outputId": "670cfbf0-8366-42d1-b630-b76363a3835a",
    "ExecuteTime": {
     "end_time": "2025-03-23T13:32:16.457944Z",
     "start_time": "2025-03-23T13:32:16.452381Z"
    }
   },
   "source": [
    "#Get our images list\n",
    "train_imgs = 'dataset/PART_1/PART_1/train.txt'\n",
    "test_imgs = 'dataset/PART_1/PART_1/test.txt'\n",
    "val_imgs = 'dataset/PART_1/PART_1/validation.txt'\n",
    "with open(train_imgs, 'r') as f:\n",
    "    train_img_list = [line.strip() for line in f.readlines()]\n",
    "\n",
    "with open(test_imgs, 'r') as f:\n",
    "    test_img_list = [line.strip() for line in f.readlines()]\n",
    "\n",
    "with open(val_imgs, 'r') as f:\n",
    "    val_img_list = [line.strip() for line in f.readlines()]\n",
    "\n",
    "print(train_img_list[0], test_img_list[0], val_img_list[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_102.jpg k2_38.jpg a_101.jpg\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2IVYECDgBOsr",
    "outputId": "e73fc9e0-c326-42e0-fd29-e61c25f3b953",
    "ExecuteTime": {
     "end_time": "2025-03-23T13:32:16.484815Z",
     "start_time": "2025-03-23T13:32:16.460712Z"
    }
   },
   "source": [
    "# Root path\n",
    "root_img_path = Path('dataset/images/')\n",
    "root_ann_path = Path('dataset/annotations/')\n",
    "\n",
    "#Split Data\n",
    "split_data(train_img_list, root_img_path, root_ann_path, 'train')\n",
    "split_data(test_img_list, root_img_path, root_ann_path, 'test')\n",
    "split_data(val_img_list, root_img_path, root_ann_path, 'val')"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T13:32:16.508020Z",
     "start_time": "2025-03-23T13:32:16.486459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import glob\n",
    "import os\n",
    "working_image_path = 'dataset/working/images/'\n",
    "working_labels_path = 'dataset/working/labels/'\n",
    "\n",
    "# Images\n",
    "img_test_path = glob.glob(os.path.join(working_image_path + '/test/' , \"*.jpg\"))\n",
    "print(f'img_test_path: {len(img_test_path)}')\n",
    "\n",
    "img_train_path = glob.glob(os.path.join(working_image_path + '/train/' , \"*.jpg\"))\n",
    "print(f'img_train_path: {len(img_train_path)}')\n",
    "\n",
    "img_val_path = glob.glob(os.path.join(working_image_path + '/val/' , \"*.jpg\"))\n",
    "print(f'img_val_path: {len(img_val_path)}')\n",
    "\n",
    "# Labels\n",
    "label_test_path = glob.glob(os.path.join(working_labels_path + '/test/' , \"*.txt\"))\n",
    "print(f'label_test_path: {len(label_test_path)}')\n",
    "\n",
    "label_train_path = glob.glob(os.path.join(working_labels_path + '/train/' , \"*.txt\"))\n",
    "print(f'label_train_path: {len(label_train_path)}')\n",
    "\n",
    "label_val_path = glob.glob(os.path.join(working_image_path + '/val/' , \"*.txt\"))\n",
    "print(f'label_val_path: {len(label_val_path)}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_test_path: 514\n",
      "img_train_path: 2787\n",
      "img_val_path: 339\n",
      "label_test_path: 514\n",
      "label_train_path: 2787\n",
      "label_val_path: 0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Train model**"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
